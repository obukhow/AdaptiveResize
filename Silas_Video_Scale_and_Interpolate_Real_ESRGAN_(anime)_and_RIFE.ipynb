{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6BPxh_VmVVIu"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/silasp/AdaptiveResize/blob/master/Silas_Video_Scale_and_Interpolate_Real_ESRGAN_(anime)_and_RIFE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRDbDYYMQt_Y"
      },
      "source": [
        "# Video upscaling and frame interpolation tool\n",
        "\n",
        "There was nothing super reliable available, so I cobbled this together.\n",
        "\n",
        "Tested on colab+ / google drive. You'll need both of these for it to work, probably.\n",
        "\n",
        "From:\n",
        "- Real-ESRGAN [GitHub repo](https://github.com/xinntao/Real-ESRGAN). \n",
        "- RIFE [GitHub repo](https://github.com/megvii-research/ECCV2022-RIFE).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BPxh_VmVVIu"
      },
      "source": [
        "# ESRGAN prep\n",
        "Before start, make sure that you choose\n",
        "* Runtime Type = Python 3\n",
        "* Hardware Accelerator = GPU\n",
        "\n",
        "in the **Runtime** menu -> **Change runtime type**\n",
        "\n",
        "Then, we clone the repository, set up the envrironment."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## See what GPU you got\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQJgGjNXjolo",
        "outputId": "e9458f7b-9fa5-4955-d9b1-8276154dfae2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct  3 21:54:21 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Parameters\n",
        "#@markdown ###Filenames and paths\n",
        "working_dir = '/content/gdrive/MyDrive/' #@param {type:\"string\"}\n",
        "original_video = 'GS7.mp4' #@param {type:\"string\"}\n",
        "x2_video = 'GS7_x2.mp4' #@param {type:\"string\"}\n",
        "hifps_x2_video = 'GS7_x2_hifps.mp4' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ###<br/>Scale the video up by this much\n",
        "video_scale=3#@param {type:\"slider\", min:1, max:5, step:1}\n",
        "\n",
        "#@markdown ####<br/>Interpolate steps: 1=2x, 2=4x, 3=8x, 4=16x (approx)\n",
        "#@markdown For example, 3 will convert a 5fps video to 40fps.\n",
        "interpolate_steps=3#@param {type:\"slider\", min:1, max:5, step:1}\n",
        "\n",
        "\n",
        "## video_path = 'upload/Gs6.mp4' #@param {type:\"string\"}\n",
        "\n",
        "video_path = working_dir + original_video\n",
        "x2_video_path = working_dir + x2_video\n",
        "hifps_x2_video_path = working_dir + hifps_x2_video\n",
        "\n",
        "\n",
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E3mWzgcny0l",
        "outputId": "3e262f32-4185-4ca7-c37e-3960249427fe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnpnrLfMV2jU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e167d652-b090-407e-f4e7-813688a8beba"
      },
      "source": [
        "# Clone Real-ESRGAN, install dependencies\n",
        "\n",
        "# Clone to gdrive if not there already\n",
        "import os\n",
        "if os.path.isdir('/content/gdrive/MyDrive/Real-ESRGAN'):\n",
        "  %cd /content/gdrive/MyDrive/Real-ESRGAN\n",
        "elif os.path.isdir('/content/gdrive/MyDrive/'):\n",
        "  %cd /content/gdrive/MyDrive\n",
        "  !git clone https://github.com/xinntao/Real-ESRGAN.git\n",
        "  %cd Real-ESRGAN\n",
        "\n",
        "# Set up the environment\n",
        "print(\"Started Installing libraries for Real-ESRGAN upscaling.\")\n",
        "!pip -q install basicsr\n",
        "!pip -q install facexlib\n",
        "!pip -q install gfpgan\n",
        "!pip -q install ffmpeg-python\n",
        "!pip -q install -r requirements.txt\n",
        "print(\"Running setup.py - this will take a while...\")\n",
        "!python setup.py develop &> /dev/null\n",
        "print(\"Finished Installing libraries for Real-ESRGAN upscaling.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Real-ESRGAN\n",
            "Started Installing libraries for Real-ESRGAN upscaling.\n",
            "\u001b[K     |████████████████████████████████| 172 kB 7.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 74.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 190 kB 95.9 MB/s \n",
            "\u001b[?25h  Building wheel for basicsr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 59 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 177 kB 15.8 MB/s \n",
            "\u001b[?25h  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 52 kB 937 kB/s \n",
            "\u001b[?25hRunning setup.py - this will take a while...\n",
            "Finished Installing libraries for Real-ESRGAN upscaling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqiEtaOYXnrt"
      },
      "source": [
        "# 5. Upscale and save upscaled video to x2_video_path\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTVL4m_zXqBU",
        "outputId": "ff128ffc-e392-4297-b1f1-c5d65e5f466e"
      },
      "source": [
        "print(\"Starting video upscale...\")\n",
        "# ! python inference_realesrgan_video.py -i upload/onepiece_demo.mp4 -n realesr-animevideov3 -s 2 --suffix outx2\n",
        "! python inference_realesrgan_video.py -i $video_path -n realesr-animevideov3 -s $video_scale --suffix outx2\n",
        " # Argements\n",
        " # -i, --input: input video\n",
        " # -n, --model_name: Used model name\n",
        " # -s, --outscale: Scale\n",
        " # -suffix: Suffix of the output video\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting video upscale...\n",
            "inference: 100% 919/919 [06:27<00:00,  2.37frame/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Move to specified path\n",
        "\n",
        "x2_workingfile_path = '/content/gdrive/MyDrive/Real-ESRGAN/results/*_outx2.mp4'\n",
        "\n",
        "!ls $x2_workingfile_path\n",
        "!mv $x2_workingfile_path $x2_video_path "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytbpy0LXlcqz",
        "outputId": "17019f29-a8b1-47f4-c965-c43d64693435"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Real-ESRGAN/results/GS7_outx2.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpolate Frames with RIFE"
      ],
      "metadata": {
        "id": "rNHQqP6ef3Qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Install RIFE\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/hzwer/arXiv2020-RIFE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYxkLxiKfrDV",
        "outputId": "d73482f1-5539-46ff-bd24-158f7d69908b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'arXiv2020-RIFE'...\n",
            "remote: Enumerating objects: 1888, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 1888 (delta 34), reused 43 (delta 19), pack-reused 1825\u001b[K\n",
            "Receiving objects: 100% (1888/1888), 4.08 MiB | 1.08 MiB/s, done.\n",
            "Resolving deltas: 100% (1187/1187), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Download the interpolation AI model \n",
        "\n",
        "!mkdir /content/arXiv2020-RIFE/train_log\n",
        "%cd /content/arXiv2020-RIFE/train_log\n",
        "!gdown --id 1APIzVeI-4ZZCEuIRE1m6WYfSCaOsi_7_\n",
        "!7z e -aoa RIFE_trained_model_v3.6.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAhxuSRvf2co",
        "outputId": "11861543-4fb2-42c2-90fe-ad3b4688307a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/arXiv2020-RIFE/train_log\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1APIzVeI-4ZZCEuIRE1m6WYfSCaOsi_7_\n",
            "To: /content/arXiv2020-RIFE/train_log/RIFE_trained_model_v3.6.zip\n",
            "100% 11.3M/11.3M [00:00<00:00, 54.2MB/s]\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 11332064 bytes (11 MiB)\n",
            "\n",
            "Extracting archive: RIFE_trained_model_v3.6.zip\n",
            "--\n",
            "Path = RIFE_trained_model_v3.6.zip\n",
            "Type = zip\n",
            "Physical Size = 11332064\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 4\n",
            "Files: 10\n",
            "Size:       12208819\n",
            "Compressed: 11332064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/arXiv2020-RIFE/\n",
        "## Demo video not needed\n",
        "## !gdown --id 1i3xlKb7ax7Y70khcTcuePi6E7crO_dFc\n",
        "!pip3 -q install -r requirements.txt\n",
        "print(\"You can safely ignore dependency errors for torchtext, torchaudio, gfpgan, fastai, basicsr and realesrgan - it works just fine without these...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn2RZFPogBmi",
        "outputId": "fe06b7a2-1219-4b99-fcc7-143df67dea5f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/arXiv2020-RIFE\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 6.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 18 kB/s \n",
            "\u001b[K     |████████████████████████████████| 388 kB 92.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 57.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.2 MB/s \n",
            "\u001b[?25h  Building wheel for moviepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.6.0 which is incompatible.\n",
            "gfpgan 1.3.8 requires torch>=1.7, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.7.9 requires torch<1.14,>=1.7, but you have torch 1.6.0 which is incompatible.\n",
            "fastai 2.7.9 requires torchvision>=0.8.2, but you have torchvision 0.7.0 which is incompatible.\n",
            "basicsr 1.4.2 requires torch>=1.7, but you have torch 1.6.0 which is incompatible.\n",
            "realesrgan 0.3.0 requires torch>=1.7, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "You can safely ignore dependency errors for torchtext, torchaudio, gfpgan, fastai, basicsr and realesrgan - it works just fine without these...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/arXiv2020-RIFE/'\n",
        "!cp $x2_video_path '/content/arXiv2020-RIFE/video.mp4'\n",
        "!ls '/content/arXiv2020-RIFE/'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsX8Ko0WgMaW",
        "outputId": "4ff1ccfd-8363-48cf-adcf-ecd2b7908898"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benchmark\t  docker\t      model\t\ttrain.py\n",
            "Colab_demo.ipynb  inference_img.py    README.md\n",
            "dataset.py\t  inference_video.py  requirements.txt\n",
            "demo\t\t  LICENSE\t      train_log\n",
            "benchmark\t  docker\t      model\t\ttrain.py\n",
            "Colab_demo.ipynb  inference_img.py    README.md\t\tvideo.mp4\n",
            "dataset.py\t  inference_video.py  requirements.txt\n",
            "demo\t\t  LICENSE\t      train_log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 inference_video.py --help\n",
        "\n",
        "print(\"Starting video interpolation...\")\n",
        "!python3 inference_video.py --exp=$interpolate_steps --video=video.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQbaiuQMiQ5B",
        "outputId": "f617b75a-d09e-4e03-8316-bb914a3126de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: inference_video.py [-h] [--video VIDEO] [--output OUTPUT] [--img IMG]\n",
            "                          [--montage] [--model MODELDIR] [--fp16] [--UHD]\n",
            "                          [--scale SCALE] [--skip] [--fps FPS] [--png]\n",
            "                          [--ext EXT] [--exp EXP]\n",
            "\n",
            "Interpolation for a pair of images\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help        show this help message and exit\n",
            "  --video VIDEO\n",
            "  --output OUTPUT\n",
            "  --img IMG\n",
            "  --montage         montage origin video\n",
            "  --model MODELDIR  directory with trained model files\n",
            "  --fp16            fp16 mode for faster and more lightweight inference on\n",
            "                    cards with Tensor Cores\n",
            "  --UHD             support 4k video\n",
            "  --scale SCALE     Try scale=0.5 for 4k video\n",
            "  --skip            whether to remove static frames before processing\n",
            "  --fps FPS\n",
            "  --png             whether to vid_out png format vid_outs\n",
            "  --ext EXT         vid_out video extension\n",
            "  --exp EXP\n",
            "Starting video interpolation...\n",
            "Loaded v3.x HD model.\n",
            "video.mp4, 919.0 frames in total, 5.0FPS to 40.0FPS\n",
            "The audio will be merged after interpolation process\n",
            "  9% 80/919.0 [02:38<26:59,  1.93s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/arXiv2020-RIFE/'\n",
        "\n",
        "## Copy back to gdrive\n",
        "!cp /content/arXiv2020-RIFE/video*fps.mp4 $hifps_x2_video_path\n",
        "\n",
        "print(\"All done - if it worked, processed video should be available at: \" + hifps_x2_video_path)"
      ],
      "metadata": {
        "id": "akrMO0JAihw1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}